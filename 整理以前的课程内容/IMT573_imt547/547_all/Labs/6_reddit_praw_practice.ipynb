{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First setup Reddit app and get the API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First install PRAW, the Python Reddit API Wrapper.\n",
    "\n",
    "pip install praw\n",
    "\n",
    "(more info https://praw.readthedocs.io/en/latest/getting_started/installation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw #pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a few other libraries for the rest of the exercise\n",
    "#from os.path import isfile\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Reddit app and get the API keys. \n",
    "Follow the steps mentioned in class. See the steps on Canvas [here](https://canvas.uw.edu/courses/1434897/files/folder/Labs?preview=72511628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"praw.ini\" file to save the application information in the following format\n",
    "**Do not share this file with others since it has your credentials and keep it in the same directory as your other Reddit scripts**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[DEFAULT]\n",
    "client_id=paste your client id here\n",
    "client_secret=paste your client secret here\n",
    "user_agent=paste your user agent here\n",
    "username=paste your Reddit username here\n",
    "password=paste your Reddit account password here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure everything is working by running the following code that creates Reddit instance\n",
    "\n",
    "The Reddit instance provides convenient access to Redditâ€™s API. [read the docs](https://praw.readthedocs.io/en/latest/code_overview/reddit_instance.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials from DEFAULT instance in praw.ini\n",
    "reddit = praw.Reddit('DEFAULT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data from a subreddit\n",
    "\n",
    "Refer to the docs for syntax and method details:\n",
    "[reddit.subreddit](https://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html?highlight=subreddit.top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by fetching the top submissions from the subreddit `r/news`\n",
    "\n",
    "If you are new to Reddit, go to the subreddit r/news to see how it looks: http://reddit.com/r/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subreddit variable like this \n",
    "# Pick any subreddit like (news, pics, science, technology, politics) or pick any other you want\n",
    "subreddit = reddit.subreddit('news')\n",
    "\n",
    "# Get top posts by \".top\" (you can also do .hot, .new, .controversial and .gilded) and put limit\n",
    "# This creates iterator item which we can use to parse posts individually\n",
    "top_subreddit = subreddit.top(limit=10)\n",
    "\n",
    "#Print titles and id of posts by iterating over the top_subreddit object\n",
    "for submission in top_subreddit:\n",
    "    print(submission.title, submission.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another quick alternative\n",
    "\n",
    "subreddit = reddit.subreddit('news')\n",
    "for submission in subreddit.top(limit=10):\n",
    "    print(submission.title, submission.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to see if you really fetched the correct data:\n",
    "\n",
    "Go here and do a quick scan: https://www.reddit.com/r/news/top/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">**TODO**:</span> Fetch the 15 hottest submissions\n",
    "\n",
    "You just fetched `top` submissions from the subreddit r/news. Using the same logic, fetch the top 10 hottest submissions from the subreddit of your choice. Quick browse through the [docs](https://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html?highlight=subreddit.top#) can help.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission object\n",
    "Let's try to explore the submission object a bit more.\n",
    "\n",
    "<span class=\"mark\">**TODO**</span>\n",
    "Apart from `title` and `id` what else can you fetch.\n",
    "\n",
    "Checkout the documentation table [here](https://praw.readthedocs.io/en/latest/code_overview/models/submission.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for submission in subreddit.top(limit=10):\n",
    "    ## Your rest of the code here\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pandas frames from subreddit related data \n",
    "\n",
    "* We will first fetch various fields from a bunch of reddit posts using the Reddit praw API. (You just did this step in the previous code blocks)\n",
    "* Next, we will create a dictionary of key:value pairs to store each of these fields\n",
    "* Finally, we will create a pandas dataframe from this dictionary.\n",
    "\n",
    "\n",
    "Note: If you are new to python and python dictionary, this is one data structure that will really come in handy. Do read how we can easily handle dictionary using [`defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can scrape different characteristics of posts (refer to Reddit API documentation to see what options are available)\n",
    "# Here we will scrape title, score, url, id, number of comments, UTC timestamp and body text\n",
    "# We will store it in a dictionary\n",
    "from collections import defaultdict\n",
    "posts_dict = defaultdict(list)\n",
    "\n",
    "# Get top posts by \".top\" (you can also do .hot, .new, .controversial and .gilded) and put limit\n",
    "# This creates iterator item which we can use to parse posts individually\n",
    "top_subreddit = subreddit.top(limit=15)\n",
    "\n",
    "# 1. If you had not used defaultdict, you had to first create a disctionary structure to store all such fields.\n",
    "#posts_dict = { \"title\":[],\"score\":[], \"id\":[], \"url\":[], \"comms_num\": [], \"created\": [], \"body\":[]}\n",
    "\n",
    "# 2. Now iterate over the top_subreddit object and store fields for each post in the disctionary\n",
    "for submission in top_subreddit:\n",
    "    posts_dict[\"title\"].append(submission.title)\n",
    "    posts_dict[\"score\"].append(submission.score) #score: The number of upvotes for the submission.\n",
    "    posts_dict[\"upvote_ratio\"].append(submission.upvote_ratio) #upvote_ratio: The percentage of upvotes from all votes on the submission.\n",
    "    posts_dict[\"id\"].append(submission.id)\n",
    "    posts_dict[\"url\"].append(submission.url)\n",
    "    posts_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    posts_dict[\"created\"].append(str(submission.created).strip('.0')) #avoid storing data in scientific format\n",
    "    posts_dict[\"orginial\"].append(submission.is_original_content) #Whether or not the submission has been set as original content.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from a dictionary\n",
    "news_data = pd.DataFrame(posts_dict)\n",
    "# Print \n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV\n",
    "news_data.to_csv('./top_15_posts_in_news.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment object\n",
    "See the [docs](https://praw.readthedocs.io/en/latest/code_overview/models/comment.html?highlight=comment) to realize the multiple fields that you can retrive from the comments object.\n",
    "\n",
    "Below is a small example. But the ways to expand this is limitless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in reddit.subreddit(\"news\").comments(limit=5):\n",
    "    print('SUBMISSION', comment.submission.title, '\\n', 'COMMENT:', comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get use profile info\n",
    "\n",
    "example user: u/karmanaut.\n",
    "\n",
    "You can also see how this user looks like on the Reddit: https://www.reddit.com/user/karmanaut\n",
    "\n",
    "Now let's programmatically get some data from this user profile\n",
    "\n",
    "More info in [Redditor](https://praw.readthedocs.io/en/latest/code_overview/models/redditor.html) doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user object\n",
    "user = reddit.redditor(\"karmanaut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user id\n",
    "print( user.id)\n",
    "\n",
    "# Know if user has verified email\n",
    "print( user.has_verified_email)\n",
    "\n",
    "#know the username (if you created the user instance with user-id instead of username)\n",
    "print( user.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">**TODO**:</span> Apart from `name` , `has_verified_email` and `id` what else can you find out about the \"user\"?\n",
    "\n",
    "*Hint*: See the Attribute table in the [Redditor](https://praw.readthedocs.io/en/latest/code_overview/models/redditor.html) documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below to extract additional fields for this user\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user comments info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user comment disctionaty to store attributes of top comments made by the user\n",
    "ucomm_dict = defaultdict(list)\n",
    "#ucomm_dict = { \"subreddit\":[],\"score\":[], \"id\":[], \"body\":[]}\n",
    "\n",
    "# Iterate over user comment object and store in dictionary \n",
    "for comment in user.comments.top(limit=50):\n",
    "    ucomm_dict['subreddit'].append(comment.subreddit)\n",
    "    ucomm_dict['score'].append(comment.score)\n",
    "    ucomm_dict['id'].append(comment.id)\n",
    "    ucomm_dict['body'].append(comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from a dictionary\n",
    "\n",
    "ucomm_data = pd.DataFrame(ucomm_dict)\n",
    "ucomm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV\n",
    "ucomm_data.to_csv(\"./user_comment_data.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability\n",
    "\n",
    "Let's find the readability of these comments.\n",
    "\n",
    "Python's `textstat` package can come in handy: https://pypi.org/project/textstat/\n",
    "\n",
    "`pip install textstat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in ucomm_data.index:\n",
    "    print(textstat.smog_index(ucomm_data['body'][ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do these values even mean?**\n",
    "\n",
    "How do we interpret the SMOG index. \n",
    "See: https://en.wikipedia.org/wiki/Gunning_fog_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas dataframe.\n",
    "\n",
    "In the previous code block you also practiced iterating over pandas dataframe.\n",
    "\n",
    "So while you are at, also checkout other ways of iterating over rows in pandas:\n",
    "\n",
    "https://www.geeksforgeeks.org/different-ways-to-iterate-over-rows-in-pandas-dataframe/\n",
    "\n",
    "You can iterate using the `loc` function that we saw last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">**TODO**</span>: \n",
    "\n",
    "The \"Fake News Packs a Lot in Title...\" paper that you read had used other three types of readability indexes (see the section on Complexity feature, pg. 3). Specifically:\n",
    "- SMOG Grade, \n",
    "- Gunning Fog, and \n",
    "- Flesh-Kincaid grade level index.\n",
    "\n",
    "You computed the SMOG index just now.\n",
    "\n",
    "Write code to find the two other readability indices for the comment data.\n",
    "\n",
    "Also, interpret the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">**TODO**:</span> *Medium difficulty*\n",
    "\n",
    "We saw how to get top posts from a subreddit, top comments for a user and also comments from a subreddit. Can you figure out how to get posts made by a user? You can take this same example user `karmanaut` and print their top posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
